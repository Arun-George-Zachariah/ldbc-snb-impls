/* 
 * Copyright (C) 2016 Stanford University
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package net.ellitron.ldbcsnbimpls.interactive.neo4j.util;

import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.FileNotFoundException;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.text.ParseException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.TimeZone;

/**
 * A utility for converting dataset files generated by the LDBC SNB Data
 * Generator[1] to the file format expected by the Neo4j import tool[2].
 * <p>
 * TODO:<br>
 * <ul>
 * <li>Add specific instructions.</li>
 * <li>Join language and e-mails into person node.</li>
 * <li>More flexible file searching for multipart files.</li>
 * </ul>
 * <p>
 * [1]: git@github.com:ldbc/ldbc_snb_datagen.git<br>
 * [2]: http://neo4j.com/docs/stable/import-tool.html<br>
 *
 * @author Jonathan Ellithorpe (jde@cs.stanford.edu)
 */
public class DataFormatConverter {

  /**
   * Represents all the types of nodes in the graph and their various
   * properties.
   */
  private enum Node {

    COMMENT("MESSAGE_ID", "id", "Comment", "comment",
        new String[]{"creationDate", "locationIP", "browserUsed", "content",
          "length"}),
    FORUM("FORUM_ID", "id", "Forum", "forum",
        new String[]{"title", "creationDate"}),
    ORGANISATION("ORGANISATION_ID", "id", "Organisation", "organisation",
        new String[]{"type", "name", "url"}),
    PERSON("PERSON_ID", "id", "Person", "person",
        new String[]{"firstName", "lastName", "gender", "birthday",
          "creationDate", "locationIP", "browserUsed", "email", "speaks"}),
    PLACE("PLACE_ID", "id", "Place", "place",
        new String[]{"name", "url", "type"}),
    POST("MESSAGE_ID", "id", "Post", "post",
        new String[]{"imageFile", "creationDate", "locationIP", "browserUsed",
          "language", "content", "length"}),
    TAG("TAG_ID", "id", "Tag", "tag",
        new String[]{"name", "url"}),
    TAGCLASS("TAGCLASS_ID", "id", "TagClass", "tagclass",
        new String[]{"name", "url"});

    /*
     * "ID space" for the node (see Neo4j Import Tool documentation). IDs
     * within an ID space must be unique. Note that Comments and Posts both
     * belong to the ID space for messages. This is because their IDs are
     * unique together in this space, and the benchmark sometimes requires
     * quering a "message" with a specific ID, which could be either a post or
     * a comment.
     */
    private final String neoIdSpace;

    /*
     * The property key used to refer to the id in Cypher queries.
     */
    private final String neoIdPropKey;

    /*
     * The label given to these nodes. We use the same labels here as used in
     * the Cypher queries for Neo4j listed in the appendix of the LDBC SNB
     * specification v0.2.2.
     */
    private final String neoLabel;

    /*
     * This is the name used in fileNames for the node as output by the LDBC
     * SNB Data Generator.
     */
    private final String fileLabel;

    /*
     * Ordered array of the properties for this node, in the order they appear
     * in the LDBC SNB Data Generator dataset files.
     */
    private final String[] props;

    private Node(String neoIdSpace, String neoIdPropKey,
        String neoLabel, String fileLabel, String[] props) {
      this.neoIdSpace = neoIdSpace;
      this.neoIdPropKey = neoIdPropKey;
      this.neoLabel = neoLabel;
      this.fileLabel = fileLabel;
      this.props = props;
    }

    public String getNeoIdSpace() {
      return neoIdSpace;
    }

    public String getNeoIdPropKey() {
      return neoIdPropKey;
    }

    public String getNeoLabel() {
      return neoLabel;
    }

    public String getFileLabel() {
      return fileLabel;
    }

    public String[] getProps() {
      return props;
    }
  }

  /**
   * Represents all the types of relationships in the graph. Each relationship
   * has a "type" which is used to refer to relationships of that type in
   * Cypher queries. This "type" is overloaded in the sense that it is also
   * part of the filenames that contain relationships of this type (e.g.
   * person_isLocatedIn_place_0_0.csv).
   */
  private enum Relationship {

    CONTAINEROF("containerOf"),
    HASCREATOR("hasCreator"),
    HASINTEREST("hasInterest"),
    HASMEMBER("hasMember"),
    HASMODERATOR("hasModerator"),
    HASTAG("hasTag"),
    HASTYPE("hasType"),
    ISLOCATEDIN("isLocatedIn"),
    ISPARTOF("isPartOf"),
    ISSUBCLASSOF("isSubclassOf"),
    KNOWS("knows"),
    LIKES("likes"),
    REPLYOF("replyOf"),
    SPEAKS("speaks"),
    STUDYAT("studyAt"),
    WORKAT("workAt");

    private final String type;

    private Relationship(String type) {
      this.type = type;
    }
  }

  private static final Map<String, String> propDataTypes;
  private static final SimpleDateFormat birthdayDateFormat;
  private static final SimpleDateFormat creationDateDateFormat;

  static {
    Map<String, String> dataTypeMap = new HashMap<>();
    dataTypeMap.put("birthday", "long");
    dataTypeMap.put("browserUsed", "string");
    dataTypeMap.put("content", "string");
    dataTypeMap.put("creationDate", "long");
    dataTypeMap.put("email", "string[]");
    dataTypeMap.put("firstName", "string");
    dataTypeMap.put("gender", "string");
    dataTypeMap.put("imageFile", "string");
    dataTypeMap.put("language", "string");
    dataTypeMap.put("lastName", "string");
    dataTypeMap.put("length", "int");
    dataTypeMap.put("locationIP", "string");
    dataTypeMap.put("name", "string");
    dataTypeMap.put("speaks", "string[]");
    dataTypeMap.put("title", "string");
    dataTypeMap.put("type", "string");
    dataTypeMap.put("url", "string");

    propDataTypes = Collections.unmodifiableMap(dataTypeMap);

    birthdayDateFormat =
        new SimpleDateFormat("yyyy-MM-dd");
    birthdayDateFormat.setTimeZone(TimeZone.getTimeZone("GMT"));
    creationDateDateFormat =
        new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss.SSSZ");
    creationDateDateFormat.setTimeZone(TimeZone.getTimeZone("GMT"));
  }

  /**
   * Print usage information.
   */
  private static void printUsage() {
    System.out.println("Usage: DataFormatConverter inputDir outputDir");
    System.out.println("  inputDir  Directory containing SNB dataset files.");
    System.out.println("  outputDir Destination directory for output files.");
  }

  /**
   * Parse a property file to coalesce multiple properties for a single id into
   * a list of those properties for the id. Used for parsing the email and
   * speaks property files for person nodes, but can be used on any node
   * property file with the same format.
   *
   * @param path Path to the property file.
   *
   * @return Map from node id to List of property values for the property
   * represented by the parsed file.
   *
   * @throws IOException
   */
  private static Map<String, List<String>> parsePropFile(Path path)
      throws IOException {
    Map<String, List<String>> propMap = new HashMap<>();
    BufferedReader propFile =
        Files.newBufferedReader(path, StandardCharsets.UTF_8);

    String line;
    propFile.readLine(); // Skip over the first line (column headers).
    while ((line = propFile.readLine()) != null) {
      String[] lineParts = line.split("\\|");
      String id = lineParts[0];
      String prop = lineParts[1];
      if (propMap.containsKey(id)) {
        propMap.get(id).add(prop);
      } else {
        List<String> list = new ArrayList<>();
        list.add(prop);
        propMap.put(id, list);
      }
    }
    propFile.close();

    return propMap;
  }

  /**
   * Serialize a list of property values into a single String formatted for the
   * Neo4j Import Tool.
   *
   * @param propList List of property values.
   *
   * @return Serialized string of property values.
   */
  private static String serializePropertyValueList(List<String> propList) {
    StringBuilder sb = new StringBuilder();
    sb.append("\"");
    for (int i = 0; i < propList.size(); i++) {
      // If not first element, start with array separator
      if (i > 0) {
        sb.append(";");
      }

      sb.append(propList.get(i));
    }
    sb.append("\"");

    return sb.toString();
  }

  public static void main(String[] args)
      throws FileNotFoundException, IOException, ParseException {
    if (args.length != 2) {
      printUsage();
      return;
    }

    String inputDir = args[0];
    String outputDir = args[1];

    // Prepare email and speaks properties to be added to Person nodes.
    String fileName =
        Node.PERSON.getFileLabel() + "_email_emailaddress_0_0.csv";
    Path path = Paths.get(inputDir + "/" + fileName);

    Map<String, List<String>> personEmail = parsePropFile(path);

    fileName = Node.PERSON.getFileLabel() + "_speaks_language_0_0.csv";
    path = Paths.get(inputDir + "/" + fileName);

    Map<String, List<String>> personSpeaks = parsePropFile(path);

    // Start with the nodes.
    for (Node node : Node.values()) {
      fileName = node.getFileLabel() + "_0_0.csv";

      path = Paths.get(inputDir + "/" + fileName);
      BufferedReader inFile =
          Files.newBufferedReader(path, StandardCharsets.UTF_8);

      path = Paths.get(outputDir + "/" + fileName);
      BufferedWriter outFile =
          Files.newBufferedWriter(path, StandardCharsets.UTF_8);

      /*
       * Replace the headers (first line) with those expected by the Neo4j
       * Import Tool.
       */
      // Skip over header line of input file.
      inFile.readLine();

      // First field is always the ID.
      outFile.append(String.format(
          "%s:ID(%s)", node.getNeoIdPropKey(), node.getNeoIdSpace()));

      // Then the properties.
      List<String> nodeProps = Arrays.asList(node.getProps());
      for (String property : nodeProps) {
        outFile.append("|" + property + ":" + propDataTypes.get(property));
      }

      // And the last field is always a label for this node type.
      outFile.append("|:LABEL\n");

      /*
       * Now go through every line of the file processing certain columns,
       * adding fields, and adding labels as necessary.
       */
      String line;
      while ((line = inFile.readLine()) != null) {
        /*
         * Date-type fields (birthday, creationDate, ...) need to be converted
         * to the number of milliseconds since January 1, 1970, 00:00:00 GMT.
         * This is the format expected to be returned for these fields by LDBC
         * SNB benchmark queries, although the format in the dataset files are
         * things like "1989-12-04" and "2010-03-17T23:32:10.447+0000". We
         * could do this conversion "live" during the benchmark, but that would
         * detract from the performance numbers' reflection of true database
         * performance since it would add to the client-side query processing
         * overhead.
         */
        String[] colVals = line.split("\\|");
        for (int i = 0; i < colVals.length; i++) {
          if (i > 0) {
            if (nodeProps.get(i - 1).equals("birthday")) {
              outFile.append(String.valueOf(
                  birthdayDateFormat.parse(colVals[i]).getTime()) + "|");
            } else if (nodeProps.get(i - 1).equals("creationDate")) {
              outFile.append(String.valueOf(
                  creationDateDateFormat.parse(colVals[i]).getTime()) + "|");
            } else {
              outFile.append(colVals[i] + "|");
            }
          } else {
            outFile.append(colVals[i] + "|");
          }
        }

        /*
         * For person nodes we merge their email and speaks properties listed
         * in their respective property files into the person node file. This
         * is because the Neo4j Import Tool does not have a way to import
         * properties separate from those listed in node and relationship
         * files.
         */
        if (node.equals(Node.PERSON)) {
          String id = colVals[0];

          // First append emails.
          if (personEmail.containsKey(id)) {
            String email = serializePropertyValueList(personEmail.get(id));
            outFile.append(email);
          }
          outFile.append("|");

          // Then append languages this person speaks.
          if (personSpeaks.containsKey(id)) {
            String speaks = serializePropertyValueList(personSpeaks.get(id));
            outFile.append(speaks);
          }
          outFile.append("|");
        }

        // Append the node's label to the end of the line.
        outFile.append(node.getNeoLabel() + "\n");
      }

      inFile.close();
      outFile.close();
    }
  }
}
